name: Canary E2E Tests

on:
  schedule:
    # Run once daily at 9 AM KST (midnight UTC)
    - cron: '0 0 * * *'
  workflow_dispatch:
    inputs:
      dry_run:
        description: 'Dry run mode (skip metrics upload)'
        required: false
        default: 'false'
        type: boolean

env:
  AWS_REGION: ap-northeast-2
  
jobs:
  canary-test:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    permissions:
      contents: read
      id-token: write
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install frontend dependencies
        run: |
          cd frontend
          npm ci

      - name: Install root dependencies for scripts
        run: npm ci

      - name: Install Playwright browsers
        run: |
          cd frontend
          npx playwright install --with-deps chromium

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Run canary E2E tests
        id: e2e
        run: |
          cd frontend
          
          # Create results directory
          mkdir -p test-results/canary
          
          # Run E2E tests with JSON reporter
          PLAYWRIGHT_JSON_OUTPUT_NAME=test-results/canary-results.json npx playwright test \
            --config=playwright.config.ts \
            --reporter=json \
            --output=test-results/canary \
            e2e/tests/ \
            --timeout=30000 \
            --retries=1
        env:
          VITE_API_URL: https://8e299o0dw4.execute-api.ap-northeast-2.amazonaws.com/v1
        continue-on-error: true

      - name: Process test results
        id: process
        run: |
          cd frontend
          # Debug: List all files in test-results directory
          echo "üîç Debugging - Contents of frontend directory:"
          find . -name "*.json" -type f | head -10
          echo "üîç Contents of test-results directory:"
          ls -la test-results/ 2>/dev/null || echo "test-results directory not found"
          
          # Check if results.json exists in various possible locations
          if [ -f "test-results/canary-results.json" ]; then
            echo "‚úÖ Found test-results/canary-results.json"
            echo "üîç First 50 lines of results file:"
            head -50 test-results/canary-results.json
            node ../scripts/process-canary-results.js test-results/canary-results.json
          elif [ -f "test-results/results.json" ]; then
            echo "‚úÖ Found test-results/results.json"
            node ../scripts/process-canary-results.js test-results/results.json
          elif [ -f "test-results.json" ]; then
            echo "‚úÖ Found test-results.json"
            node ../scripts/process-canary-results.js test-results.json
          else
            echo "‚ùå No test results file found, creating basic failure metric"
            echo "Available files:"
            find . -name "*results*.json" -o -name "*test*.json" 2>/dev/null || echo "No JSON files found"
            mkdir -p test-results/canary
            echo '{"timestamp":"'$(date -u +%Y-%m-%dT%H:%M:%S.%3NZ)'","namespace":"Conduit/E2E","metrics":[{"MetricName":"SuccessRate","Value":0,"Unit":"Percent","Timestamp":"'$(date -u +%Y-%m-%dT%H:%M:%S.%3NZ)'"},{"MetricName":"ProcessingError","Value":1,"Unit":"Count","Timestamp":"'$(date -u +%Y-%m-%dT%H:%M:%S.%3NZ)'"}]}' > test-results/canary/metrics.json
          fi
        continue-on-error: true

      - name: Upload metrics to CloudWatch
        if: steps.process.conclusion == 'success' && github.event.inputs.dry_run != 'true'
        run: |
          # Read processed metrics (script saves to test-results/metrics.json)
          METRICS_FILE="frontend/test-results/metrics.json"
          if [ -f "$METRICS_FILE" ]; then
            echo "‚úÖ Found metrics file at: $METRICS_FILE"
            cat "$METRICS_FILE"
            node scripts/upload-metrics.js "$METRICS_FILE"
          else
            echo "‚ùå Metrics file not found at: $METRICS_FILE"
            echo "üîç Available files in test-results:"
            ls -la frontend/test-results/ || echo "No test-results directory"
            echo "Creating basic failure metric..."
            aws cloudwatch put-metric-data \
              --namespace "Conduit/E2E" \
              --metric-data MetricName=SuccessRate,Value=0,Unit=Percent,Timestamp=$(date -u +%Y-%m-%dT%H:%M:%S.000Z)
          fi

      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: canary-test-results-${{ github.run_id }}
          path: |
            frontend/test-results/
          retention-days: 7

      - name: Report status
        if: always()
        run: |
          echo "Canary test completed"
          echo "E2E Status: ${{ steps.e2e.outcome }}"
          echo "Process Status: ${{ steps.process.outcome }}"
          if [ -f "frontend/test-results/canary/metrics.json" ]; then
            echo "Metrics generated:"
            cat frontend/test-results/canary/metrics.json
          fi